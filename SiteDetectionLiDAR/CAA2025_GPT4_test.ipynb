{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juergenlandauer/caa2025/blob/main/SiteDetectionLiDAR/CAA2025_GPT4_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic site detection in satellite and LiDAR images with GPT4 by Open AI\n",
        "\n",
        "Author: Juergen Landauer (juergen (AT) landauer-ai.de)\n",
        "\n",
        "To start, first go to the \"Input parameters\" section below and review or (optionally) adjust parameters. Then run the entire Notebook by choosing Runtime->Run all in the menu above.\n"
      ],
      "metadata": {
        "id": "Dx7MT7aUemmK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8g4hTRotheH"
      },
      "source": [
        "### Set up your API key and install the Open AI Python SDK\n",
        "\n",
        "To access GPT-4, you need to provide your OpenAI API key. Follow these steps:\n",
        "\n",
        "- register with Open AI\n",
        "- Open your [`OpenAI Settings`](https://platform.openai.com/settings) page. Click `User API keys` then `Create new secret key` to generate new token.\n",
        "Click `Copy`. This will place your private key in the clipboard.\n",
        "- In Colab, go to the left pane and click on `Secrets` (ðŸ”‘).\n",
        "- Store OpenAI API key under the name `OPENAI_API_KEY`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mN8x8DPgu9Kv"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6lYXRcjthKV"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input parameters\n",
        "\n",
        "Review all parameters in this section and (optionally) adjust them on the right side. For example, you can upload your own input zip file by providing an URL."
      ],
      "metadata": {
        "id": "_Yr1IaV0_Lk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Demo with English hillforts for CAA2025\n",
        "\n",
        "Feel free to replace this with your own imagery by providing a download URL (e.g. from Google Drive)\n",
        "\n",
        "Note that the ZIP file must contain two sub-folders called \"sites\" and \"nonsites\", resp. Each folder must then contain images of sites or samples of other landscape (non-sites)\n"
      ],
      "metadata": {
        "id": "XiarFXMU6rmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_ZIP_URL = 'https://www.dropbox.com/scl/fi/uubtlqbw62o1gi7n9542x/EnglandHillforts.zip?rlkey=dmewcvtgeoiuh9zu02qwfls4u&st=grvt8nyt&dl=0' # @param {\"allow-input\":true}"
      ],
      "metadata": {
        "id": "R-kCVqNJIadX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The text 'prompt' sent to the Foundation Model.\n",
        "\n",
        "Play with different variations of the text and don't forget to include the object type you are looking for."
      ],
      "metadata": {
        "id": "y_7102DV6545"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = 'This is a LiDAR image possibly containing archaeological features from England, possibly also enclosures or hillforts.' # @param {\"allow-input\":true}"
      ],
      "metadata": {
        "id": "OI53sja3-7gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This appendix to the prompt ensures that the AI response is formatted in the right way. Do NOT change this!!!\n"
      ],
      "metadata": {
        "id": "zOrjQz3OhSi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT += \" For each of the objects in this image return its type, its probability and bounding box in JSON format like [xmin ymin xmax, ymax].\""
      ],
      "metadata": {
        "id": "wlJfbiH97czk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The text response from the AI is sometimes ambiguous. If you only (or \"strictly\") want to see certain types of responses, then keep this to True and provide a list of keywords you want to see in the output. Make sure you do not mess up the list syntax."
      ],
      "metadata": {
        "id": "xP3C63n08MzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STRICT_RESPONSE_FILTERING = True # @param ['True', 'False']\n",
        "\n",
        "FILTER_KEYWORDS = [\"hillfort\", \"enclosure\"]  # @param {\"allow-input\":true}"
      ],
      "metadata": {
        "id": "1fnFowtk0GyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define the model we are using. Usually it is not required to change this."
      ],
      "metadata": {
        "id": "nwcoPsP4hZw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"gpt-4.1-mini\" # @param [\"gpt-4.1-mini\",\"gpt-4.1-nano\", \"gpt-4.1\"] {\"allow-input\":true, isTemplate: true}\n"
      ],
      "metadata": {
        "id": "BgU53fR9wFIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We load the data and unzip it into the directory 'input'"
      ],
      "metadata": {
        "id": "d5T9IqkTHa_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf input output file.zip\n",
        "!mkdir -p input/\n",
        "!wget -O file.zip \"$INPUT_ZIP_URL\"\n",
        "!unzip -q file.zip -d input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-bmrrBbHTFD",
        "outputId": "bbf1e807-bfe4-44eb-a179-16e884c739d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-22 08:25:43--  https://www.dropbox.com/scl/fi/uuirq92v5evwy8znojxje/sites.zip?rlkey=xycrlu44gdqmo5k5j439tzca7&dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.80.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.80.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc98a5a6724e244e5f9bf6b33832.dl.dropboxusercontent.com/cd/0/inline/CoSKMAyMH6W-pHxWCKJ14T8r12QT2IeZItO7TpaAbIpW944YpxwiMp3exfTtgJY3mlOOYz4PBQxvav5aWq8BSAThawOGigBKxXecg0JL9zaUmJ62oYYwMvT3NpUHAjE1X1w/file# [following]\n",
            "--2025-04-22 08:25:44--  https://uc98a5a6724e244e5f9bf6b33832.dl.dropboxusercontent.com/cd/0/inline/CoSKMAyMH6W-pHxWCKJ14T8r12QT2IeZItO7TpaAbIpW944YpxwiMp3exfTtgJY3mlOOYz4PBQxvav5aWq8BSAThawOGigBKxXecg0JL9zaUmJ62oYYwMvT3NpUHAjE1X1w/file\n",
            "Resolving uc98a5a6724e244e5f9bf6b33832.dl.dropboxusercontent.com (uc98a5a6724e244e5f9bf6b33832.dl.dropboxusercontent.com)... 162.125.80.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc98a5a6724e244e5f9bf6b33832.dl.dropboxusercontent.com (uc98a5a6724e244e5f9bf6b33832.dl.dropboxusercontent.com)|162.125.80.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CoSM9M2BdL6_nFDUn4KVBK5eGRYXLNZ_IeWxYyu4P8wm2otxPVxL0dR9SPghrB5Y1tWC4riP-jNYI2GY7iaj-HnJEG5n9zYR792c41d_DlCpBYwTriocrklZGbx35Ad7B4mzZISXQy8TM2viPui8lZRm-i7jbhz80oAVMU4gMaAWWLbAHgYGI3GUYsn2FVvOGVU3mIdK_W-9QSRhc3NjxnhLJofQPvL94lyFkdtN0_XWZ1tU3D6oI0zT7o8UFezWURBrcVLE2wcrKyPTrF1sIsd4teDdyGdPcrUX_UqWI1otdJB36rkseiq8c3MhgkCo7bOEbpqp3gvXVHukPKykGQLSR9qfmLp1Wdym-92LivOeeg/file [following]\n",
            "--2025-04-22 08:25:44--  https://uc98a5a6724e244e5f9bf6b33832.dl.dropboxusercontent.com/cd/0/inline2/CoSM9M2BdL6_nFDUn4KVBK5eGRYXLNZ_IeWxYyu4P8wm2otxPVxL0dR9SPghrB5Y1tWC4riP-jNYI2GY7iaj-HnJEG5n9zYR792c41d_DlCpBYwTriocrklZGbx35Ad7B4mzZISXQy8TM2viPui8lZRm-i7jbhz80oAVMU4gMaAWWLbAHgYGI3GUYsn2FVvOGVU3mIdK_W-9QSRhc3NjxnhLJofQPvL94lyFkdtN0_XWZ1tU3D6oI0zT7o8UFezWURBrcVLE2wcrKyPTrF1sIsd4teDdyGdPcrUX_UqWI1otdJB36rkseiq8c3MhgkCo7bOEbpqp3gvXVHukPKykGQLSR9qfmLp1Wdym-92LivOeeg/file\n",
            "Reusing existing connection to uc98a5a6724e244e5f9bf6b33832.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56072141 (53M) [application/zip]\n",
            "Saving to: â€˜file.zipâ€™\n",
            "\n",
            "file.zip            100%[===================>]  53.47M  34.0MB/s    in 1.6s    \n",
            "\n",
            "2025-04-22 08:25:46 (34.0 MB/s) - â€˜file.zipâ€™ saved [56072141/56072141]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we import some libraries"
      ],
      "metadata": {
        "id": "fYvXD4rvEEQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2 as cv\n",
        "import PIL.Image\n",
        "import json\n",
        "import random\n",
        "import io\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from PIL import ImageColor\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "import time\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from google.colab import files as colabfiles"
      ],
      "metadata": {
        "id": "7G5Uxbp6EDEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some utility functions we use"
      ],
      "metadata": {
        "id": "0Hl5k_B3iqQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to read the images as PIL\n",
        "def read_pil(fpath):\n",
        "  pilimg = PIL.Image.open(fpath)\n",
        "  return pilimg"
      ],
      "metadata": {
        "id": "Bf1ZbZkvg_mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to encode the image\n",
        "import base64 # Import the base64 module\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
      ],
      "metadata": {
        "id": "aMY1ILN_Mqcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to plot bounding boxes on images\n",
        "def plot_bounding_boxes(img, results):\n",
        "    width, height = img.size\n",
        "    # Create a drawing object\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    fpath='/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf'\n",
        "    fontsize = 24\n",
        "    font = ImageFont.truetype(fpath, fontsize)\n",
        "\n",
        "    noun_phrase, prob, bbox = results\n",
        "\n",
        "    if len(bbox) != 4: return # nothing found\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    # Ensure x1 <= x2 and y1 <= y2\n",
        "    x1, x2 = sorted([x1, x2])  # Sort x-coordinates\n",
        "    y1, y2 = sorted([y1, y2])  # Sort y-coordinates\n",
        "\n",
        "    color = 'yellow'\n",
        "    # Draw the bounding box\n",
        "    draw.rectangle(((x1, y1), (x2, y2)), outline=color, width=4)\n",
        "    # Draw the text\n",
        "    draw.text((x1 + 8, y1 + 6), noun_phrase+\" \"+str(prob), fill=color, font=font)"
      ],
      "metadata": {
        "id": "Pw7UfuMZPL47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# process folder"
      ],
      "metadata": {
        "id": "hqncD_OCLXnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read files\n",
        "sites = glob('./input/sites/*.*')\n",
        "nonsites = glob('./input/nonsites/*.*')\n",
        "len(sites), len(nonsites)"
      ],
      "metadata": {
        "id": "hh2zNw_MK6-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea897ef-cbbc-4f42-b282-c34fa105d6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(379, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment this if you want to try just a small sample of MAX_N for each class\n",
        "#import random\n",
        "#MAX_N = 10\n",
        "\n",
        "#sites = random.sample(sites, MAX_N)\n",
        "#nonsites = random.sample(nonsites, MAX_N)"
      ],
      "metadata": {
        "id": "X14BfYxwAAHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the output format of a 'Detection' - CURRENTLY UNUSED HERE!\n",
        "from pydantic import BaseModel\n",
        "class Detection(BaseModel):\n",
        "  detection_type: str\n",
        "  probability: float\n",
        "  bbox: list[int]"
      ],
      "metadata": {
        "id": "4DpEbr7-qMQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing all files with GPT-4"
      ],
      "metadata": {
        "id": "6Sg3gTZv4w_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output\n",
        "!mkdir output"
      ],
      "metadata": {
        "id": "I-tCniW3kGXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = sites + nonsites\n",
        "\n",
        "with open('./output/phrases.txt', 'w') as docfile:\n",
        "  for fpath in files:\n",
        "    img = read_pil(fpath)\n",
        "    img.save('./tmp.png')\n",
        "    base64_image = encode_image(\"./tmp.png\")\n",
        "    print('________________________________________________________')\n",
        "\n",
        "    response_format = Detection\n",
        "\n",
        "    response = client.responses.create(\n",
        "        model = MODEL,\n",
        "        temperature = 0.3,\n",
        "        input=[{\n",
        "           \"role\": \"user\",\n",
        "           \"content\": [\n",
        "              {\"type\": \"input_text\", \"text\": PROMPT},\n",
        "              {\"type\": \"input_image\", \"image_url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
        "        },],}],\n",
        "        text={\n",
        "          \"format\": {\n",
        "              \"type\": \"json_schema\",\n",
        "              \"name\": \"Detection\",\n",
        "            \"schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"detection_type\": {\n",
        "                        \"type\": \"string\"\n",
        "                    },\n",
        "                    \"probability\": {\n",
        "                        \"type\": \"number\"\n",
        "                    },\n",
        "                    \"bbox\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"number\"\n",
        "                        }\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"detection_type\", \"probability\", \"bbox\"],\n",
        "                \"additionalProperties\": False\n",
        "            },\n",
        "            \"strict\":True\n",
        "          },},)\n",
        "\n",
        "    outlist = response.output_text\n",
        "    outlist = re.findall(r'({.+?})', outlist) # possibly cut into results list (if more than one result)\n",
        "\n",
        "    for out in outlist:\n",
        "      ret = json.loads(out)\n",
        "      if STRICT_RESPONSE_FILTERING and any(element in out.lower() for element in FILTER_KEYWORDS) and float(ret['probability']) >= 0.5:\n",
        "        FOUND = True\n",
        "        plot_bounding_boxes(img, (ret['detection_type'],ret['probability'], ret['bbox']))\n",
        "      else: FOUND = False\n",
        "\n",
        "      print (fpath, \"------\", FOUND, \"---\", ret)\n",
        "      display(img.resize(size=(384,384)))\n",
        "\n",
        "    filename = Path(fpath).name\n",
        "    img.save(Path('output')/filename)\n",
        "    docfile.write(\"--- \" + fpath + \":\" + json.dumps(outlist) + os.linesep)\n",
        "    time.sleep(5)"
      ],
      "metadata": {
        "id": "p-z1QcI5MymQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export results for download\n",
        "We now open a file download dialog for the output.zip. Simply store the output in your local computer. Done :-)\n",
        "\n",
        "output.zip contains all images with bounding box annotations and a file phrases.txt containing the original response from Gemini.\n",
        "\n"
      ],
      "metadata": {
        "id": "bEriipIF22Fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r output.zip output\n",
        "colabfiles.download('output.zip')"
      ],
      "metadata": {
        "id": "wJNheETmcYqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AE1-K5HR4Za7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}